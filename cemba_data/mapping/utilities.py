import configparser
import os
import subprocess
import logging
import pathlib

# logger
import pandas as pd

log = logging.getLogger(__name__)
log.addHandler(logging.NullHandler())


def get_configuration(config_path=None):
    """
    Read .ini config file from given path
    """
    ref_path_config = configparser.ConfigParser()
    if config_path is None:
        log.info('config path not provided, use default config')
        ref_path_config.read(os.path.dirname(__file__) + '/mapping_config.ini')
    else:
        ref_path_config.read(config_path)
    return ref_path_config


def test_cmd(tool_name, cmd_list):
    try:
        subprocess.run(cmd_list, stderr=subprocess.PIPE, check=True)
    except subprocess.CalledProcessError as e:
        log.error(f'Test {tool_name} got returncode {e.returncode}')
        log.error(e.stderr)
        raise
    return


def valid_environments(config):
    log.info('Test mapping environments')

    # test cutadapt
    test_cmd(tool_name='cutadapt', cmd_list=['cutadapt', '-h'])
    # test samtools
    test_cmd(tool_name='samtools', cmd_list=['samtools'])
    # test picard
    test_cmd(tool_name='picard', cmd_list=['picard'])
    # test bismark
    test_cmd(tool_name='bismark', cmd_list=['bismark', '-h'])
    # test bowtie2
    test_cmd(tool_name='bowtie2', cmd_list=['bowtie2', '--version'])
    # test pigz
    test_cmd(tool_name='pigz', cmd_list=['pigz', '-V'])

    bismark_dir = pathlib.Path(config['bismark']['bismark_reference'])
    if not bismark_dir.is_dir():
        raise TypeError(f"Bismark reference must be a directory contain a sub-dir named Bisulfite_Genome, "
                        f"generated by bismark_genome_preparation. Got a file path")
    if not bismark_dir.exists():
        raise FileNotFoundError(f"Bismark reference directory not found. "
                                f"Path in the config.ini is {bismark_dir}")

    allc_ref_fasta = pathlib.Path(config['callMethylation']['reference_fasta'])
    allc_ref_fai = pathlib.Path(config['callMethylation']['reference_fasta'] + '.fai')
    if not allc_ref_fasta.exists():
        raise FileNotFoundError(f"Reference fasta for ALLC generation not found. "
                                f"Path in the config.ini is {allc_ref_fasta}")
    if not allc_ref_fai.exists():
        raise FileNotFoundError(f".fai index for reference fasta not found. "
                                f"Path of fadix should be {allc_ref_fai}. "
                                f"You can use 'samtools fadix {allc_ref_fasta}' to generate.")
    return


def validate_fastq_dataframe(fastq_dataframe):
    """
    Check if fastq_dataframe is
    1. have required columns
    2. uid is unique
    """
    if isinstance(fastq_dataframe, str):
        fastq_dataframe = pd.read_csv(fastq_dataframe, index_col=None, sep='\t')

    for required in ['uid', 'lane', 'read_type', 'fastq_path']:
        if required not in fastq_dataframe.columns:
            raise ValueError(f'column {required} not in fastq dataframe columns, '
                             f'remember that the 4 required columns of fastq dataframe are: '
                             f'uid, lane, read_type, fastq_path. '
                             f'The orders do not matter, but the names need to be exact.')

    for _, df in fastq_dataframe.groupby(['lane', 'read_type']):
        if df['uid'].unique().size != df['uid'].size:
            raise ValueError('uid column are not unique for each lane and read-type combination.')

    # modify fastq dataframe column names
    fastq_dataframe.columns = [column.replace('-', '_') for column in fastq_dataframe.columns]

    # modify fastq columns, because '_' is used in file name and we split by '_'
    # I know this is stupid...
    fastq_dataframe['uid'] = fastq_dataframe['uid'].apply(lambda i: i.replace('_', '-'))
    fastq_dataframe['lane'] = fastq_dataframe['lane'].apply(lambda i: i.replace('_', '-'))
    fastq_dataframe['read_type'] = fastq_dataframe['read_type'].apply(lambda i: i.replace('_', '-'))
    return fastq_dataframe
